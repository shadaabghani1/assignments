{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Horse-or-Human.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk6y-yhbKMVk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "d01984fd-84f3-4bf9-dc9e-c78f04102386"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2aZrTxzKjTK"
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/Colab Notebooks/horse-or-human.zip\" -d \"/content/drive/My Drive/Colab Notebooks/training\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75Adz1qWLEG3"
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/Colab Notebooks/validation-horse-or-human.zip\" -d \"/content/drive/My Drive/Colab Notebooks/test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlo5rDZEWJd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "25aea2f0-cca2-4147-cf61-0811b5b446fd"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks')\n",
        "os.listdir()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Copy of Welcome To Colaboratory',\n",
              " 'horse-or-human.zip',\n",
              " 'horses',\n",
              " 'humans',\n",
              " 'validation-horse-or-human.zip',\n",
              " 'test',\n",
              " 'training',\n",
              " 'Untitled0.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVjaFODPWSls"
      },
      "source": [
        "traindir='training'\n",
        "testdir='test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZdu6QiJL6_x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "371702c7-e42c-4c88-c7c8-959300a52636"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D,Dense,Flatten\n",
        "from keras import losses"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBIoGzEhWc0l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "17af896b-a9e1-4d6f-d3ad-407583caf590"
      },
      "source": [
        "datagen=ImageDataGenerator(rescale=1./255)\n",
        "train=datagen.flow_from_directory(traindir,batch_size=32,shuffle=True,class_mode='binary')\n",
        "test=datagen.flow_from_directory(testdir,batch_size=32,shuffle=True,class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P_HIl0wW3FK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "458f3971-ba06-4363-9d04-840876ea23e7"
      },
      "source": [
        "dataiter=iter(train)\n",
        "images,labels=dataiter.next()\n",
        "print(images.shape)\n",
        "print(images[1].shape)\n",
        "print(labels[1].item())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 256, 256, 3)\n",
            "(256, 256, 3)\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZFI_I-hXqL0"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(4, (3,3), strides=2, activation='relu', input_shape=(256, 256, 3)),\n",
        "      tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "      tf.keras.layers.Conv2D(8,(3,3), activation='relu' ),\n",
        "      tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
        "      # tf.keras.layers.Conv2D(32,(3,3), activation='relu' ),\n",
        "      # tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
        "      tf.keras.layers.Conv2D(16,(3,3), activation='relu' ),\n",
        "      tf.keras.layers.MaxPooling2D(pool_size= (2,2)),\n",
        "      tf.keras.layers.Conv2D(32,(3,3), activation='relu' ),\n",
        "      tf.keras.layers.MaxPooling2D(pool_size =(2,2)),\n",
        "      tf.keras.layers.Conv2D(64,(3,3), activation='relu' ),\n",
        "      tf.keras.layers.MaxPooling2D(pool_size = (2,2)),   \n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(512, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.5),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfZefcIoeAZ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "1b48ca92-edb9-44b2-95f8-ea3cc6d46459"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 127, 127, 4)       112       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 63, 63, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 61, 61, 8)         296       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 30, 30, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 16)        1168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 12, 12, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 4, 4, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 156,809\n",
            "Trainable params: 156,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnSX7msbuyxg"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClPaEceUka2x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "234c69ab-9954-4bfb-fa4e-b4443ab0dd59"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train ,\n",
        "    steps_per_epoch=32,  \n",
        "    epochs= 80,\n",
        "    verbose=1,\n",
        "    validation_data = test,\n",
        "    validation_steps=32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "31/32 [============================>.] - ETA: 7s - loss: 0.6117 - acc: 0.6729 Epoch 1/80\n",
            "32/32 [==============================] - 184s 6s/step - loss: 0.8088 - acc: 0.6484\n",
            "32/32 [==============================] - 441s 14s/step - loss: 0.6051 - acc: 0.6774 - val_loss: 0.8088 - val_acc: 0.6484\n",
            "Epoch 2/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.2157 - acc: 0.9214Epoch 1/80\n",
            "32/32 [==============================] - 7s 227ms/step - loss: 0.7780 - acc: 0.8359\n",
            "32/32 [==============================] - 21s 645ms/step - loss: 0.2095 - acc: 0.9216 - val_loss: 0.7780 - val_acc: 0.8359\n",
            "Epoch 3/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9605Epoch 1/80\n",
            "32/32 [==============================] - 7s 229ms/step - loss: 0.8440 - acc: 0.8477\n",
            "32/32 [==============================] - 20s 632ms/step - loss: 0.1132 - acc: 0.9598 - val_loss: 0.8440 - val_acc: 0.8477\n",
            "Epoch 4/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9730Epoch 1/80\n",
            "32/32 [==============================] - 8s 234ms/step - loss: 0.7569 - acc: 0.8438\n",
            "32/32 [==============================] - 20s 637ms/step - loss: 0.0819 - acc: 0.9739 - val_loss: 0.7569 - val_acc: 0.8438\n",
            "Epoch 5/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9699Epoch 1/80\n",
            "32/32 [==============================] - 8s 240ms/step - loss: 0.9362 - acc: 0.8438\n",
            "32/32 [==============================] - 20s 639ms/step - loss: 0.0757 - acc: 0.9698 - val_loss: 0.9362 - val_acc: 0.8438\n",
            "Epoch 6/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9823Epoch 1/80\n",
            "32/32 [==============================] - 8s 246ms/step - loss: 0.8624 - acc: 0.8711\n",
            "32/32 [==============================] - 21s 642ms/step - loss: 0.0442 - acc: 0.9829 - val_loss: 0.8624 - val_acc: 0.8711\n",
            "Epoch 7/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9927Epoch 1/80\n",
            "32/32 [==============================] - 8s 248ms/step - loss: 1.1157 - acc: 0.8633\n",
            "32/32 [==============================] - 20s 635ms/step - loss: 0.0217 - acc: 0.9930 - val_loss: 1.1157 - val_acc: 0.8633\n",
            "Epoch 8/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9844Epoch 1/80\n",
            "32/32 [==============================] - 8s 256ms/step - loss: 1.3401 - acc: 0.8594\n",
            "32/32 [==============================] - 20s 637ms/step - loss: 0.0386 - acc: 0.9849 - val_loss: 1.3401 - val_acc: 0.8594\n",
            "Epoch 9/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9879Epoch 1/80\n",
            "32/32 [==============================] - 8s 257ms/step - loss: 1.0186 - acc: 0.8672\n",
            "32/32 [==============================] - 21s 647ms/step - loss: 0.0443 - acc: 0.9883 - val_loss: 1.0186 - val_acc: 0.8672\n",
            "Epoch 10/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9904Epoch 1/80\n",
            "32/32 [==============================] - 9s 267ms/step - loss: 1.8458 - acc: 0.8398\n",
            "32/32 [==============================] - 20s 629ms/step - loss: 0.0266 - acc: 0.9907 - val_loss: 1.8458 - val_acc: 0.8398\n",
            "Epoch 11/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9896Epoch 1/80\n",
            "32/32 [==============================] - 9s 269ms/step - loss: 1.2180 - acc: 0.8633\n",
            "32/32 [==============================] - 20s 635ms/step - loss: 0.0315 - acc: 0.9899 - val_loss: 1.2180 - val_acc: 0.8633\n",
            "Epoch 12/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9970Epoch 1/80\n",
            "32/32 [==============================] - 8s 264ms/step - loss: 1.3297 - acc: 0.8633\n",
            "32/32 [==============================] - 20s 630ms/step - loss: 0.0083 - acc: 0.9971 - val_loss: 1.3297 - val_acc: 0.8633\n",
            "Epoch 13/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9979Epoch 1/80\n",
            "32/32 [==============================] - 9s 270ms/step - loss: 1.9221 - acc: 0.8516\n",
            "32/32 [==============================] - 20s 619ms/step - loss: 0.0127 - acc: 0.9979 - val_loss: 1.9221 - val_acc: 0.8516\n",
            "Epoch 14/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9960Epoch 1/80\n",
            "32/32 [==============================] - 8s 265ms/step - loss: 1.5799 - acc: 0.8633\n",
            "32/32 [==============================] - 20s 628ms/step - loss: 0.0112 - acc: 0.9961 - val_loss: 1.5799 - val_acc: 0.8633\n",
            "Epoch 15/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9927Epoch 1/80\n",
            "32/32 [==============================] - 8s 265ms/step - loss: 1.1435 - acc: 0.8828\n",
            "32/32 [==============================] - 20s 627ms/step - loss: 0.0236 - acc: 0.9930 - val_loss: 1.1435 - val_acc: 0.8828\n",
            "Epoch 16/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 1.0000    Epoch 1/80\n",
            "32/32 [==============================] - 9s 268ms/step - loss: 3.2820 - acc: 0.7969\n",
            "32/32 [==============================] - 20s 629ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 3.2820 - val_acc: 0.7969\n",
            "Epoch 17/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9979Epoch 1/80\n",
            "32/32 [==============================] - 9s 268ms/step - loss: 0.4704 - acc: 0.9141\n",
            "32/32 [==============================] - 20s 624ms/step - loss: 0.0133 - acc: 0.9970 - val_loss: 0.4704 - val_acc: 0.9141\n",
            "Epoch 18/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 5.2985e-04 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 266ms/step - loss: 1.5567 - acc: 0.8672\n",
            "32/32 [==============================] - 20s 627ms/step - loss: 5.1377e-04 - acc: 1.0000 - val_loss: 1.5567 - val_acc: 0.8672\n",
            "Epoch 19/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 7.9996e-05 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 266ms/step - loss: 1.5229 - acc: 0.8750\n",
            "32/32 [==============================] - 20s 623ms/step - loss: 7.8210e-05 - acc: 1.0000 - val_loss: 1.5229 - val_acc: 0.8750\n",
            "Epoch 20/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9914Epoch 1/80\n",
            "32/32 [==============================] - 9s 269ms/step - loss: 1.3680 - acc: 0.8633\n",
            "32/32 [==============================] - 20s 609ms/step - loss: 0.0331 - acc: 0.9917 - val_loss: 1.3680 - val_acc: 0.8633\n",
            "Epoch 21/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 9.3360e-04 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 268ms/step - loss: 1.7226 - acc: 0.8633\n",
            "32/32 [==============================] - 20s 621ms/step - loss: 9.2797e-04 - acc: 1.0000 - val_loss: 1.7226 - val_acc: 0.8633\n",
            "Epoch 22/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 1.7200e-04 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 269ms/step - loss: 1.7298 - acc: 0.8672\n",
            "32/32 [==============================] - 20s 629ms/step - loss: 1.6829e-04 - acc: 1.0000 - val_loss: 1.7298 - val_acc: 0.8672\n",
            "Epoch 23/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9904Epoch 1/80\n",
            "32/32 [==============================] - 9s 269ms/step - loss: 2.2291 - acc: 0.8555\n",
            "32/32 [==============================] - 19s 607ms/step - loss: 0.0446 - acc: 0.9907 - val_loss: 2.2291 - val_acc: 0.8555\n",
            "Epoch 24/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 2.0823e-04 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 276ms/step - loss: 1.7120 - acc: 0.8711\n",
            "32/32 [==============================] - 20s 625ms/step - loss: 2.0576e-04 - acc: 1.0000 - val_loss: 1.7120 - val_acc: 0.8711\n",
            "Epoch 25/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 1.1261e-04 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 263ms/step - loss: 1.8881 - acc: 0.8750\n",
            "32/32 [==============================] - 20s 622ms/step - loss: 1.0941e-04 - acc: 1.0000 - val_loss: 1.8881 - val_acc: 0.8750\n",
            "Epoch 26/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 6.3612e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 264ms/step - loss: 2.0403 - acc: 0.8711\n",
            "32/32 [==============================] - 20s 617ms/step - loss: 6.2575e-06 - acc: 1.0000 - val_loss: 2.0403 - val_acc: 0.8711\n",
            "Epoch 27/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9907Epoch 1/80\n",
            "32/32 [==============================] - 8s 264ms/step - loss: 2.9854 - acc: 0.8281\n",
            "32/32 [==============================] - 20s 611ms/step - loss: 0.0347 - acc: 0.9910 - val_loss: 2.9854 - val_acc: 0.8281\n",
            "Epoch 28/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 2.2769e-04 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 265ms/step - loss: 2.7515 - acc: 0.8281\n",
            "32/32 [==============================] - 19s 600ms/step - loss: 2.2227e-04 - acc: 1.0000 - val_loss: 2.7515 - val_acc: 0.8281\n",
            "Epoch 29/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 9.2534e-05 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 263ms/step - loss: 2.1709 - acc: 0.8633\n",
            "32/32 [==============================] - 20s 619ms/step - loss: 8.9902e-05 - acc: 1.0000 - val_loss: 2.1709 - val_acc: 0.8633\n",
            "Epoch 30/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 7.1724e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 266ms/step - loss: 2.1136 - acc: 0.8711\n",
            "32/32 [==============================] - 19s 605ms/step - loss: 7.5847e-06 - acc: 1.0000 - val_loss: 2.1136 - val_acc: 0.8711\n",
            "Epoch 31/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9948Epoch 1/80\n",
            "32/32 [==============================] - 9s 266ms/step - loss: 2.1641 - acc: 0.8672\n",
            "32/32 [==============================] - 20s 610ms/step - loss: 0.0245 - acc: 0.9950 - val_loss: 2.1641 - val_acc: 0.8672\n",
            "Epoch 32/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 2.4559e-05 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 267ms/step - loss: 2.0566 - acc: 0.8711\n",
            "32/32 [==============================] - 19s 606ms/step - loss: 2.3879e-05 - acc: 1.0000 - val_loss: 2.0566 - val_acc: 0.8711\n",
            "Epoch 33/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 9.4755e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 268ms/step - loss: 1.9098 - acc: 0.8789\n",
            "32/32 [==============================] - 20s 612ms/step - loss: 9.3455e-06 - acc: 1.0000 - val_loss: 1.9098 - val_acc: 0.8789\n",
            "Epoch 34/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 2.8347e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 7s 215ms/step - loss: 1.8501 - acc: 0.8789\n",
            "32/32 [==============================] - 18s 558ms/step - loss: 2.7397e-06 - acc: 1.0000 - val_loss: 1.8501 - val_acc: 0.8789\n",
            "Epoch 35/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 2.2802e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 7s 220ms/step - loss: 2.0895 - acc: 0.8789\n",
            "32/32 [==============================] - 20s 636ms/step - loss: 2.2266e-06 - acc: 1.0000 - val_loss: 2.0895 - val_acc: 0.8789\n",
            "Epoch 36/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9990Epoch 1/80\n",
            "32/32 [==============================] - 7s 222ms/step - loss: 2.1678 - acc: 0.8828\n",
            "32/32 [==============================] - 20s 639ms/step - loss: 0.0144 - acc: 0.9980 - val_loss: 2.1678 - val_acc: 0.8828\n",
            "Epoch 37/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 7.0952e-05 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 235ms/step - loss: 2.0681 - acc: 0.8789\n",
            "32/32 [==============================] - 20s 629ms/step - loss: 6.8798e-05 - acc: 1.0000 - val_loss: 2.0681 - val_acc: 0.8789\n",
            "Epoch 38/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 2.6423e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 235ms/step - loss: 2.0628 - acc: 0.8828\n",
            "32/32 [==============================] - 21s 642ms/step - loss: 2.7812e-06 - acc: 1.0000 - val_loss: 2.0628 - val_acc: 0.8828\n",
            "Epoch 39/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 3.5828e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 241ms/step - loss: 2.0680 - acc: 0.8828\n",
            "32/32 [==============================] - 20s 628ms/step - loss: 3.4933e-06 - acc: 1.0000 - val_loss: 2.0680 - val_acc: 0.8828\n",
            "Epoch 40/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 5.3485e-07 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 245ms/step - loss: 1.9868 - acc: 0.8906\n",
            "32/32 [==============================] - 21s 644ms/step - loss: 5.1857e-07 - acc: 1.0000 - val_loss: 1.9868 - val_acc: 0.8906\n",
            "Epoch 41/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1796 - acc: 0.9882Epoch 1/80\n",
            "32/32 [==============================] - 8s 255ms/step - loss: 2.5321 - acc: 0.8633\n",
            "32/32 [==============================] - 20s 629ms/step - loss: 0.1744 - acc: 0.9886 - val_loss: 2.5321 - val_acc: 0.8633\n",
            "Epoch 42/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 7.3444e-04 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 260ms/step - loss: 1.9102 - acc: 0.8828\n",
            "32/32 [==============================] - 20s 636ms/step - loss: 7.1252e-04 - acc: 1.0000 - val_loss: 1.9102 - val_acc: 0.8828\n",
            "Epoch 43/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 9.6590e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 266ms/step - loss: 1.8286 - acc: 0.8828\n",
            "32/32 [==============================] - 20s 634ms/step - loss: 9.3669e-06 - acc: 1.0000 - val_loss: 1.8286 - val_acc: 0.8828\n",
            "Epoch 44/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 1.6355e-05 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 265ms/step - loss: 1.8848 - acc: 0.8867\n",
            "32/32 [==============================] - 21s 642ms/step - loss: 1.5861e-05 - acc: 1.0000 - val_loss: 1.8848 - val_acc: 0.8867\n",
            "Epoch 45/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 1.6976e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 272ms/step - loss: 2.1959 - acc: 0.8828\n",
            "32/32 [==============================] - 20s 616ms/step - loss: 2.0294e-06 - acc: 1.0000 - val_loss: 2.1959 - val_acc: 0.8828\n",
            "Epoch 46/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9979Epoch 1/80\n",
            "32/32 [==============================] - 9s 273ms/step - loss: 1.4923 - acc: 0.9062\n",
            "32/32 [==============================] - 20s 627ms/step - loss: 0.0097 - acc: 0.9980 - val_loss: 1.4923 - val_acc: 0.9062\n",
            "Epoch 47/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9970Epoch 1/80\n",
            "32/32 [==============================] - 9s 267ms/step - loss: 2.6707 - acc: 0.8594\n",
            "32/32 [==============================] - 20s 636ms/step - loss: 0.0091 - acc: 0.9971 - val_loss: 2.6707 - val_acc: 0.8594\n",
            "Epoch 48/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 3.3922e-04 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 269ms/step - loss: 2.5514 - acc: 0.8750\n",
            "32/32 [==============================] - 20s 626ms/step - loss: 3.2914e-04 - acc: 1.0000 - val_loss: 2.5514 - val_acc: 0.8750\n",
            "Epoch 49/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 2.2793e-05 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 268ms/step - loss: 2.4579 - acc: 0.8789\n",
            "32/32 [==============================] - 20s 612ms/step - loss: 2.2317e-05 - acc: 1.0000 - val_loss: 2.4579 - val_acc: 0.8789\n",
            "Epoch 50/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 3.5645e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 266ms/step - loss: 2.5990 - acc: 0.8828\n",
            "32/32 [==============================] - 20s 630ms/step - loss: 3.4679e-06 - acc: 1.0000 - val_loss: 2.5990 - val_acc: 0.8828\n",
            "Epoch 51/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 1.1955e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 269ms/step - loss: 3.2037 - acc: 0.8594\n",
            "32/32 [==============================] - 20s 617ms/step - loss: 1.2453e-06 - acc: 1.0000 - val_loss: 3.2037 - val_acc: 0.8594\n",
            "Epoch 52/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1439 - acc: 0.9879Epoch 1/80\n",
            "32/32 [==============================] - 9s 273ms/step - loss: 5.1873 - acc: 0.8164\n",
            "32/32 [==============================] - 20s 640ms/step - loss: 0.1394 - acc: 0.9883 - val_loss: 5.1873 - val_acc: 0.8164\n",
            "Epoch 53/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 1.9132e-05 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 272ms/step - loss: 5.0185 - acc: 0.8203\n",
            "32/32 [==============================] - 20s 625ms/step - loss: 1.8638e-05 - acc: 1.0000 - val_loss: 5.0185 - val_acc: 0.8203\n",
            "Epoch 54/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 1.5408e-05 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 263ms/step - loss: 4.6336 - acc: 0.8398\n",
            "32/32 [==============================] - 20s 613ms/step - loss: 1.4984e-05 - acc: 1.0000 - val_loss: 4.6336 - val_acc: 0.8398\n",
            "Epoch 55/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 9.5936e-05 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 268ms/step - loss: 6.9235 - acc: 0.7617\n",
            "32/32 [==============================] - 20s 628ms/step - loss: 0.0014 - acc: 0.9990 - val_loss: 6.9235 - val_acc: 0.7617\n",
            "Epoch 56/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9990Epoch 1/80\n",
            "32/32 [==============================] - 8s 263ms/step - loss: 4.9922 - acc: 0.8203\n",
            "32/32 [==============================] - 20s 617ms/step - loss: 0.0023 - acc: 0.9990 - val_loss: 4.9922 - val_acc: 0.8203\n",
            "Epoch 57/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 5.9994e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 268ms/step - loss: 4.9233 - acc: 0.8281\n",
            "32/32 [==============================] - 20s 622ms/step - loss: 5.8172e-06 - acc: 1.0000 - val_loss: 4.9233 - val_acc: 0.8281\n",
            "Epoch 58/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 9.0705e-07 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 270ms/step - loss: 5.0356 - acc: 0.8281\n",
            "32/32 [==============================] - 20s 618ms/step - loss: 8.7795e-07 - acc: 1.0000 - val_loss: 5.0356 - val_acc: 0.8281\n",
            "Epoch 59/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 6.1569e-07 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 264ms/step - loss: 5.2887 - acc: 0.8242\n",
            "32/32 [==============================] - 20s 612ms/step - loss: 6.2116e-07 - acc: 1.0000 - val_loss: 5.2887 - val_acc: 0.8242\n",
            "Epoch 60/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9948Epoch 1/80\n",
            "32/32 [==============================] - 8s 265ms/step - loss: 2.5997 - acc: 0.8828\n",
            "32/32 [==============================] - 20s 616ms/step - loss: 0.0141 - acc: 0.9950 - val_loss: 2.5997 - val_acc: 0.8828\n",
            "Epoch 61/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9989Epoch 1/80\n",
            "32/32 [==============================] - 9s 267ms/step - loss: 4.9941 - acc: 0.8438\n",
            "32/32 [==============================] - 19s 607ms/step - loss: 0.0032 - acc: 0.9990 - val_loss: 4.9941 - val_acc: 0.8438\n",
            "Epoch 62/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 2.7392e-05 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 268ms/step - loss: 2.8507 - acc: 0.8828\n",
            "32/32 [==============================] - 20s 611ms/step - loss: 2.6559e-05 - acc: 1.0000 - val_loss: 2.8507 - val_acc: 0.8828\n",
            "Epoch 63/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 2.5282e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 268ms/step - loss: 2.9419 - acc: 0.8828\n",
            "32/32 [==============================] - 20s 621ms/step - loss: 2.4492e-06 - acc: 1.0000 - val_loss: 2.9419 - val_acc: 0.8828\n",
            "Epoch 64/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 3.8131e-07 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 274ms/step - loss: 4.0420 - acc: 0.8633\n",
            "32/32 [==============================] - 20s 614ms/step - loss: 3.6973e-07 - acc: 1.0000 - val_loss: 4.0420 - val_acc: 0.8633\n",
            "Epoch 65/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 1.7144e-07 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 268ms/step - loss: 3.0692 - acc: 0.8867\n",
            "32/32 [==============================] - 19s 608ms/step - loss: 1.6623e-07 - acc: 1.0000 - val_loss: 3.0692 - val_acc: 0.8867\n",
            "Epoch 66/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 7.5305e-09 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 269ms/step - loss: 3.1588 - acc: 0.8867\n",
            "32/32 [==============================] - 20s 610ms/step - loss: 7.3065e-09 - acc: 1.0000 - val_loss: 3.1588 - val_acc: 0.8867\n",
            "Epoch 67/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 7.7501e-09 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 7s 221ms/step - loss: 3.7226 - acc: 0.8711\n",
            "32/32 [==============================] - 20s 622ms/step - loss: 7.5081e-09 - acc: 1.0000 - val_loss: 3.7226 - val_acc: 0.8711\n",
            "Epoch 68/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9936Epoch 1/80\n",
            "32/32 [==============================] - 7s 224ms/step - loss: 1.8898 - acc: 0.8867\n",
            "32/32 [==============================] - 20s 637ms/step - loss: 0.0727 - acc: 0.9938 - val_loss: 1.8898 - val_acc: 0.8867\n",
            "Epoch 69/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 4.5378e-05 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 7s 233ms/step - loss: 1.9035 - acc: 0.8867\n",
            "32/32 [==============================] - 21s 649ms/step - loss: 4.4134e-05 - acc: 1.0000 - val_loss: 1.9035 - val_acc: 0.8867\n",
            "Epoch 70/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 4.5636e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 236ms/step - loss: 1.9347 - acc: 0.8867\n",
            "32/32 [==============================] - 21s 645ms/step - loss: 4.4403e-06 - acc: 1.0000 - val_loss: 1.9347 - val_acc: 0.8867\n",
            "Epoch 71/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9938Epoch 1/80\n",
            "32/32 [==============================] - 8s 244ms/step - loss: 3.5858 - acc: 0.8359\n",
            "32/32 [==============================] - 21s 649ms/step - loss: 0.0331 - acc: 0.9940 - val_loss: 3.5858 - val_acc: 0.8359\n",
            "Epoch 72/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 4.1227e-05 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 246ms/step - loss: 3.6005 - acc: 0.8398\n",
            "32/32 [==============================] - 20s 641ms/step - loss: 4.0296e-05 - acc: 1.0000 - val_loss: 3.6005 - val_acc: 0.8398\n",
            "Epoch 73/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 1.2882e-05 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 254ms/step - loss: 3.7136 - acc: 0.8398\n",
            "32/32 [==============================] - 21s 648ms/step - loss: 1.2491e-05 - acc: 1.0000 - val_loss: 3.7136 - val_acc: 0.8398\n",
            "Epoch 74/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 4.8899e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 259ms/step - loss: 3.6559 - acc: 0.8477\n",
            "32/32 [==============================] - 21s 644ms/step - loss: 4.7413e-06 - acc: 1.0000 - val_loss: 3.6559 - val_acc: 0.8477\n",
            "Epoch 75/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 2.0136e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 260ms/step - loss: 3.9099 - acc: 0.8477\n",
            "32/32 [==============================] - 20s 635ms/step - loss: 1.9590e-06 - acc: 1.0000 - val_loss: 3.9099 - val_acc: 0.8477\n",
            "Epoch 76/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9960Epoch 1/80\n",
            "32/32 [==============================] - 8s 262ms/step - loss: 5.2532 - acc: 0.8242\n",
            "32/32 [==============================] - 21s 643ms/step - loss: 0.0295 - acc: 0.9951 - val_loss: 5.2532 - val_acc: 0.8242\n",
            "Epoch 77/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 1.1149e-04 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 270ms/step - loss: 4.2581 - acc: 0.8516\n",
            "32/32 [==============================] - 20s 628ms/step - loss: 1.0821e-04 - acc: 1.0000 - val_loss: 4.2581 - val_acc: 0.8516\n",
            "Epoch 78/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 1.4813e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 267ms/step - loss: 4.1962 - acc: 0.8555\n",
            "32/32 [==============================] - 20s 622ms/step - loss: 1.4364e-06 - acc: 1.0000 - val_loss: 4.1962 - val_acc: 0.8555\n",
            "Epoch 79/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 5.9652e-06 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 9s 269ms/step - loss: 3.6227 - acc: 0.8594\n",
            "32/32 [==============================] - 20s 624ms/step - loss: 5.7839e-06 - acc: 1.0000 - val_loss: 3.6227 - val_acc: 0.8594\n",
            "Epoch 80/80\n",
            "31/32 [============================>.] - ETA: 0s - loss: 4.0673e-07 - acc: 1.0000Epoch 1/80\n",
            "32/32 [==============================] - 8s 265ms/step - loss: 3.3651 - acc: 0.8672\n",
            "32/32 [==============================] - 20s 630ms/step - loss: 3.9524e-07 - acc: 1.0000 - val_loss: 3.3651 - val_acc: 0.8672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9yfUnn4FzZU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}